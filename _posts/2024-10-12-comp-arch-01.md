---
layout: post
title: "Computer Architecture 01: Computer Architecture INTRO & Program Performance"
date: 2024-10-01 11:47 +0900
description: 
category: [Computer Science, Computer Architecture]
tags: [comp_arch, MIPS, ISA]
pin: false
math: true
mermaid: true
toc: true
---

<h2>1. Course Intro</h2>  

<h3>Classes of Computers</h3>  
1. PC  
2. Server computer  
3. Super computer  
4. Embedded computer  

<h3>8가지 아이디어 in Computer Architecture</h3>  
1. Design for Moore's Law  
2. Use abstraction to simplify design  
3. Make the common case fast  
4. Performance via parallelism  
5. Performance via pipelining  
6. Performance via prediction  
7. Hierachy of memories  
8. Dependability via redundancy  

<h3>Below your Program</h3>  
Applicaton S/W -> System S/W -> H/W와 같은 계층구조를 가지고 있다.  
1. Application S/W  
HLL(High Level Language)로 작성되었으며, 매우 느린 편이다.  
2. System S/W  
단순한 저수준의 명령어만 실행 가능한 S/W로,  
하드웨어와 응용 S/W 사이에 일어나는 과정을 추상화하는데 초점을 맞춘 S/W이다.  
- OS  
User Program과 H/W 간의 Interface 역할을 한다.  
컴퓨터 내 자원에 대한 서비스 및 감독 기능을 제공한다.  
I/O 관리나 메모리 및 스토리지 할당, 스케쥴링 등을 제공한다.  
- Compiler  
HLL -> Assembly language 번역을 담당한다.  
3. H/W  
Processor, memory, I/O Controllers가 예시이다.  

<h3>Levels of Program Code</h3>  
1. High-Level Language  
사람이 이해하기 쉽게 작성된 프로그래밍 언어로, 가독성이 높고 간단하다.  
컴파일러는 HLL를 어셈블리어로 바꿔준다.  
2. Assembly Language  
기계어를 기호 형태로 표현한 것이다. '대부분'의 Machine Code와 1:1로 매칭된다.  
어셈블러는 Assembly Code를 Machine Code로 변환해준다.  
3. Machine Language  
이진수로 표현된 하드웨어 표현 방식의 언어이다. instruction으로 표현되며, 컴퓨터 구조에 따라 사용하는 기계어가 달라진다.  

<h3>5 Main Components of a Computer</h3>  
1. Input  
2. Output  
3. Memory  
4. Datapath  
5. Control  
Input/Output은 화면이나 키보드, 마우스 등을 말한다.  
Datapath와 Control은 Processor이다.(=CPU)  
우선, 프로세서는 메모리에서 명령어와 데이터를 읽는다.  
Datapath는 연산을 수행하고 Control Unit은 데이터패스, 메모리, 입출력 장치의 동작을 결정하는 신호를 보낸다.  
입력장치는 메모리에 데이터를 쓰고, 출력장치는 메모리에서 데이터를 읽는다.  

<h2>2. What is ISA?</h2>  
만약 세탁기를 이용하는 사용자가 있다고 해보자, 이 사용자는 세탁기의 세탁 시간, 세탁할 옷감 종류 등 옵션을 선택하고 세탁 버튼을 눌러 세탁을 한다. 그러나, 추상화가 이뤄지지 않은 세탁기가 있다고 해보자. 사용자는 각운동량 법칙에 근거해서 얼마의 토크로 세탁통을 돌려 빨래를 할 것인지, 물의 온도는 사용자가 옷감의 종류에 따라 직접 헹굼 시 수온을 계산해서 적용시켜야 한다. 즉, 우리는 추상화가 잘 된 세탁기를 이용하기에 사용 시에 불편함이 전혀 없다.  

컴퓨터도 마찬가지이다.  
실제로 CPU나 메모리 등 H/W단에서 굉장히 복잡한 연산 및 제어가 일어나고 있지만,  
실제 우리는 이 동작에 대한 고려없이 OS를 이용하고 프로그램 코드를 짜곤 한다.  
즉, H/W와 S/W 간의 추상화가 잘 이뤄졌기 때문이라고 볼 수 있다.  
그리고, H/W와 최하위 S/W 간의 인터페이스가 굉장히 중요한데,  
이를 ISA(Instruction Set Architecture)라고 하며, H/W 전체를 추상화해주는 인터페이스이다.  
동일한 ISA 위에서는 여러가지 구현이 가능하며, ISA를 통해 다른 컴퓨터 간의 동일한 응용 s/w 실행이 가능해졌지만, 새로운 ISA가 등장하면 기존 S/W는 실행되지 않는 문제가 있다.  

<h2>3. Performance</h2>  
> 사실상 Chapter 01의 가장 중요한 부분이라고 할 수 있다.  

Performance(성능)은 무엇의 영향을 받을까?  
1. 알고리즘  
실행하는 연산 개수를 결정한다. (컴퓨터 구조과목에서 다루기는 부분은 아니다.)  
2. 프로그래밍 언어, 컴파일러, architecture(ISA)  
하나의 연산이 일어날 때의 machine instruction의 개수를 결정한다.(중요)  
3. Processor와 메모리 시스템  
instruction이 실행되는 속도가 얼마나 빠른지를 결정한다.(중요)  
4. I/O 시스템
컴퓨터 구조 과목에서 주요하게 다루지는 않는다.  

**[무어의 법칙]**  
집적회로의 용량이 18~24 개월마다 2배가 된다는 법칙이다.  
capacity(용량)이 늘어나고 성능이 좋아진다고 해서 2배 빨라진다는 건 아니다.  

**[성능 평가 기준]**  
예시를 하나 들어보겠다.  
400km의 거리를 승용차로 가면 100km/h로 갈 수 있고, 버스로 가면 80km/h로 갈 수 있다.   어느 것이 더 좋은 방법인가?  
당연히 승용차로 가면 4시간, 버스로 가면 5시간이 걸리기 때문에 승용차로 가는 것이 좋다고 대답할 것이다.  
그러나, 몇 가지 조건을 더 추가해보면 이야기가 달라진다.  
승용차는 4명이 탈 수 있고, 버스는 60명이 탈 수 있다고 해보자.  
승용차는 4명을 4시간에 수송하므로, 시간당 1명을 수송하는 셈인데 반해,  
버스는 60명을 5시간에 수송하므로, 시간당 12명을 수송한다.  
어느 거싱 더 좋은 방법인가?  
이 경우엔 버스가 더 좋은 방법이라고 대답할 것이다.  

즉, Measure Point를 어디에 두느냐에 따라서 성능이 결정된다.  
위의 예시에서 첫 번째로 들었던 평가 기준을 Response Time(응답 시간),  
두 번째로 들었던 평가 기준을 Throughput(또는 Bandwidth)으로 이해하면,  
컴퓨터의 성능을 평가하는 기준에 대해서 전부 이해한 것과 다름없다.  

<h3>Response Time & Throughput</h3>  
1. Response Time  
latency라고도 하고, execution time이라고도 한다.  
얼마나 주어진 job/task를 빨리 처리하느냐를 판단하는 성능 평가 기준이다.  

2. Throughput  
한번에 얼마나 많은 job을 돌릴 수 있는지를 평가하는 기준이다.  
일반적으로, (total work)/(unit time)로 계산한다.  

그렇다면, processor를 더 빠른 걸로 갈아끼우면 Response Time과 Throughput이 어떻게 변할까?  
일반적으로, Response Time이 줄고, Throughtput이 증가한다. 당연하다.  
그렇다면, processor를 여러 개 더 추가하면 어떻게 될까?  
Response Time이 동일하고, Throughput이 증가할 수도 있고, Response Time이 줄고, Throughput은 동일할 수도 있다.(실행하는 Job을 어떻게 정의하느냐에 따라 달라진다.)  

대부분의 시스템에서는 Response Time과 Throughput이 반비례하기 때문에 동시에 성능 기준을 좋게 만드는 것은 쉽지 않다.  

**여기서는 실행 시간(Response Time, Execution Time, Latency)에만 초점을 맞춰서 설명한다.**

성능은 다음과 같이 정의된다.  
$$
Performance_X = \frac{1}{Execution\,Time_X}
$$  

여기서 `X가 Y보다 n배 더 빠르다`의 의미는 다음과 같다.  
$$
\frac{Performance_X}{Performance_Y} = \frac{Execution\,Time_Y}{Execution\,Time_X} = n
$$  

<h3>Measuring Execution Time</h3>  
성능 측정에는 Elasped Time(Processing, I/O, OS overhead 다 포함한 시간)도 있지만,  
여기서는 CPU Time만 본다.  

**[CPU Time]**  
주어진 job에 대해서 얼만큼의 processing의 시간이 걸리는지만 보는 것이다.  
user CPU time과 system CPU time (둘을 구분하는 것은 쉽지 않다)이 있지만 여기서는 user CPU time에 집중한다.  
user CPU time은 프로그램 자체에 소비된 CPU 시간. 즉, 프로그램에 있는 코드를 실행했을 때 걸리는 시간을 의미한다.  
또한, CPU 관점에서는 `clock`을 기반으로 성능을 측정한다.  
H/W에서 이벤트가 발생하면 1이 되고, 다시 0이 되었다가 1이 되는 이 사이클을 clock cycle이라고 한다.  
Clock Frequency(Clock Rate)는 1초에 얼마만큼의 cycle를 도는지를 나타내며,  
Clock Period(Clock Cycle Time)는 한 사이클에 얼만큼의 시간이 걸리는지를 나타낸다.  

$$
Clock\,period = \frac{1}{Clock\,rate}
$$  
둘은 역수 관계이다.  

예를 들어, 250ps의 Clock Period가 주어지면, Clock Rate는 다음과 같이 구한다.  
250ps = 250 \times $10^{-12}$ s이다.  
따라서 역수를 취해주면, $\frac{10^{12}}{250}$를 계산하고, $4 \times 10^{9}$Hz이며,  
답은 `4GHz`이다.  



<h3>CPU Time</h3>  
$$
CPU\,Time = CPU\,Clock\,Cycle \times Clock\,Cyle\,Time = \frac{CPU\,Clock\,Cycle}{Clock\,Rate}
$$  
다음 공식은 꼭 기억하자.  
CPU의 Clock cyle을 줄이거나 Clock rate 그러니까 1초에 더 많은 cycle을 돌리면 성능이 좋아진다.  

<h3>Instruction Count, CPI & Performance</h3>  
Instruction Count는 하나의 프로그램을 실행하는데 필요한 Instruction의 개수이다.  
CPI는 Clock-cycles Per Instruction의 약자로, CPU에 의해 결정된다.  
그러나 CPI는 instruction(add, mul, lw, sw, ..)마다 다르기 때문에 우리는 Average CPI를 이용해 CPU Time을 계산할 것이다.  

예를 들어보자.  

| Instructions |    CPI    | Instruction Count |
| :----------: | :-------: | :---------------: |
|     add      | 3 cycles  |       100개       |
|     sll      | 2 cycles  |       100개       |
|     mul      | 6 cycles  |       200개       |
|     mem      | 10 cycles |       300개       |

위와 같은 instruction mix가 있다고 했을 때,  
CPI와 IC의 곱을 통해 각 instruction 당 총 clock cycles를 계산한다. 모든 instructions에 대한 clock cycle을 합해준 다음 총 Instruction Count로 나눠준다.  
따라서, 위의 Avg CPI는 약 6.4 Cycles/instruction 이라고 계산할 수 있다.  
정리한 공식이다.  

$$
Clock\,Cyles = \sum\limits_{i=1}^{n}(CPI_i \times Instruction\,Count_i)
$$ 

$$
Avg.\,CPI = \frac{Clock\,Cyles}{Instruction\,Count} = \sum\limits_{i=1}^{n}(CPI_i \times \frac{Instruction\,Count_i}{Instruction\,Count})
$$

여기서, CPU Time을 재정의한다.  
Clock Cycles를 구하는 방법을 알았으므로 다음과 같은 최종 공식이 등장한다.  

$$
CPU\,Time = \frac{(Instruction\,Count)\times(Avg.\,CPI)}{Clock\,Rate}
$$  
빈도수만 알아도 CPI를 구할 수 있다.(Frequency)  

여기서 주의해야 할 것은 ISA 구조가 같은 경우만 CPI가 기준이 도니다.  

<h2>4. Power Wall & Multiprocessor</h2>  

<h3>Power</h3>  

$$
Power \propto \frac{1}{2} \times (Capacity\,load) \times Voltage^2 \times Frequency
$$  

참고만 하자. 우리가 컨트롤 할 수 있는 부분은 Frequency이고 일반적으로 Frequency를 높여야 CPU Time이 줄어들지만, Power가 증가되는 문제가 생기다.  
더 큰 배터리 용량이 필요하다는 것이다.  
하지만, Power의 증가는 전압을 줄이고, 열을 줄여야 하는데, 현실적인 한계에 부딪히게 된다.  

<h3>From Uniprocessor To Multiprocessor</h3>  

Multiprocessor란 Multicore microprocessors이다.  
CPU를 여러 개 달아서 처리량 개선에 효과를 주는 방법이다.  
이로 인해, 명시적인 병렬 프로그래밍을 하는 것이 필요해졌는데,  
굉장히 어려운 작업이다. 구현도 어렵고 Load balancing을 어떻게 할지, communication과 synchronization에 대한 최적화는 어떻게 할지 결정하는 것이 어렵기 때문이다.  

<h2>5. Amdahl's Law & MIPS</h2>  

- Fallacy: 오류로, 많은 사람들이 공통적으로 잘못 알고 있는 부분을 의미한다.  
- Pitfall: 흔히 저지르기 쉬운 실수를 의미한다.  

여기서 소개하는 오류는 다음과 같다.  
`이용률이 낮은 컴퓨터는 전력 소모가 적다.`  
하지만, i7 CPU 벤치마크나 구글 데이터 센터의 서버들의 사례를 보더라도 쉽게 잘못된 사실이라는 것을 파악할 수 있다.  
i7에서는 CPU 100%를 썼을 때 258W를 소모하는데, 10%를 로드했을 때 121W 즉, 47%나 전력 소모가 일어난다.  
구글 데이터 센터의 대부분 서버는 10~50%만 load하고 100% 로드되는 건 전체 시간의 1%도 되지 않는다.  

**[Amdahl's law]**
어떤 개선책으로부터 얻을 수 있는 성능의 증가는 개선된 부분이 얼마나 많이 사용되느냐에 따라 제한된다는 법칙이다.  
$$
T_new = \frac{T_affected}{improvement\,factor} + T_unaffected
$$  

예를 들어, 수행시간 100초 중 80초를 multiply에 사용하는 시스템이 있다고 가정하자.  
multiply의 성능이 5배의 성능 향상을 이뤄낼 수 있을까?  
시스템 수행 시간은 `100/5=20`초가 되어야 한다.  
따라서, Amdahl's Law에 따라 `20 = 80/Speed_Up + 20`를 계산하려고 봤을 때,  
Speed_Up은 무한대로, multiply의 속도를 향상 시켜도 5배 이상의 성능 향상은 불가능하다.  

**[Millions of Instructions Per Second]**  
여기서의 MIPS는 MIPS코드와는 전혀 다르다.  
MIPS란, 실행 시간 대신 쓸 수 있는 성능 평가 척도로, 프로그램의 실행 속도를 백만 개의 명령어 단위로 나타낸 것이다.  

$$
MIPS = \frac{Clock\,rate}{CPI \times 10^6}
$$  

<h2>6. RISC vs. CISC</h2>  
- RISC  
MIPS arch, ARM, PowerPC 등이 해당된다.  
Instruction 개수 자체를 줄이는 ISA라고 생각하면 된다.  
- CISC  
Intel 8080, x86 arch. 등이 해당된다.  
복잡한 Instruction을 사용해 빠른 컴퓨터를 만드는 구조이다.  

현재 추세는 점점 RISC로 바뀌고 있다.  
더 단순한 ISA의 더 단순한 instruction을 이용해 더 빠른 실행을 도모한다.  
